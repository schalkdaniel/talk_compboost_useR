\documentclass[10pt]{beamer}\usepackage[]{graphicx}\usepackage[]{color}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}

%% include header:
\input{./header}

%% include template:
\input{./templates/metropolis_cert}



%% kableExtra stuff:
%% ----------------------------------------

\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}


%% Title:
%% ----------------------------------------

\title{compboost}
\subtitle{Fast and Flexible Way of bla}
\date{\today}
\author{Daniel Schalk}
\institute{LMU Munich\\Working Group Computational Statistics}

%% Wrap Shaded around Shunk to have a nices R output:
%% --------------------------------------------------

\let\Oldkframe\kframe
\let\endOldkframe\endkframe

\renewenvironment{kframe}
 {\scriptsize\definecolor{shadecolor}{RGB}{240,240,240}\begin{Shaded}\Oldkframe}
 {\endOldkframe\end{Shaded}\normalsize}

%% Prevent code from printing over margin:
%% --------------------------------------------------



%% Content:
%% ----------------------------------------
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}







%% SETUP Chunk:
%% ----------------------------------------



\maketitle



\section{Use-Case}

\begin{frame}{Use-Case}

\begin{itemize}
  \item
    We own a small booth at the city center that sells beer.

  \item
    As we are very interested in our customers' health, we only sell to customers who we expect to drink less than 110 liters per year.

  \item
    To estimate how much a customer drinks, we have collected data from 200 customers in recent years.

  \item
    These data include the beer consumption (in liter), age, sex, country of origin, weight, body size, and 200 characteristics gained from app usage (that have absolutely no influence).
\end{itemize}

\end{frame}

\begin{frame}[fragile]{Use-Case}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{table}[H]
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}{rllrrrrr}
\toprule
\textbf{beer\_consumption} & \textbf{gender} & \textbf{country} & \textbf{age} & \textbf{weight} & \textbf{height} & \textbf{app\_usage1} & \textbf{app\_usage2}\\
\midrule
\rowcolor{gray!6}  106.5 & m & Seychelles & 33 & 87.17 & 172.9 & 0.1680 & 0.6063\\
85.5 & f & Seychelles & 52 & 89.38 & 200.4 & 0.8075 & 0.9376\\
\rowcolor{gray!6}  116.5 & f & Czechia & 54 & 92.03 & 178.7 & 0.3849 & 0.2644\\
67.0 & m & Australia & 32 & 63.53 & 186.3 & 0.3277 & 0.3801\\
\rowcolor{gray!6}  43.0 & f & Australia & 51 & 64.73 & 175.0 & 0.6021 & 0.8075\\
\addlinespace
85.0 & m & Austria & 43 & 95.74 & 173.2 & 0.6044 & 0.9781\\
\rowcolor{gray!6}  79.0 & f & Austria & 55 & 87.65 & 156.3 & 0.1246 & 0.9579\\
107.0 & f & Austria & 24 & 93.17 & 161.4 & 0.2946 & 0.7627\\
\rowcolor{gray!6}  57.0 & m & USA & 55 & 76.27 & 182.5 & 0.5776 & 0.5096\\
89.0 & m & USA & 16 & 72.21 & 203.3 & 0.6310 & 0.0645\\
\bottomrule
\end{tabular}}
\end{table}


\end{knitrout}

\end{frame}


\begin{frame}{Use-Case}

With these data we want to answer the following questions:

\begin{itemize}
  \item
    Which of the customers' characteristics are important to be able to determine the consumption?
  \item
    How does the effect of important features look like?
  \item
    How does the model behave on unseen data?
\end{itemize}

\end{frame}




\section{What is Component-Wise Boosting?}

\begin{frame}{The General Idea}

\begin{center}
\includegraphics[width=\textwidth]{./images/cboost_gif_norisk.png}
\end{center}

\end{frame}

\begin{frame}{}

  \begin{itemize}

    \item
      Inherent (unbiased) feature selection.

    \item
      Resulting model is sparse since important effects are selected first and therefore it is able to learn in high-dimensional feature spaces ($p \gg n$).

    \item
      Parameters are updated iteratively. Therefore, the whole trace of how the model evolves is available.

  \end{itemize}

\end{frame}




\section{The Idea Behind Compboost}

\begin{frame}{About Compboost}


The \texttt{compboost} package is a fast and flexible framework for model-based boosting:

\begin{itemize}

  \item
    With \texttt{mboost} as standard, we want to keep the modular principle of defining custom base-learner and losses.

  \item
    Completely written in \texttt{C++} and exposed by \texttt{Rcpp} to obtain high performance and full memory control.

  \item
    \texttt{R} API is written in \texttt{R6} to provide convenient wrapper.

  \item
    Major parts of the \texttt{compboost} functionality are unit tested against \texttt{mboost} to ensure correctness.

\end{itemize}

\end{frame}


\begin{frame}{Runtime and Memory Considerations}

\begin{itemize}

  \item
    Matrices are stored (if possible) as sparse matrix.

  \item
    Take advantage of the matrix structure to speed up the algorithm by reducing the number of repetitive or too expensive calculations.

  \item
    Optimizer are parallelized via openmp:
    % \begin{figure}
    % \begin{center}
    % \includegraphics[width=0.7\textwidth]{./images/cboost_runtime.pdf}
    % \end{center}
    % \caption{figure was made by training 5000 iteration with just spline base-learners}
    % \end{figure}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}

{\centering \includegraphics[width=0.7\textwidth]{figure/unnamed-chunk-4-1} 

}



\end{knitrout}

\end{itemize}

\end{frame}


\section{A Short Demonstration}

\begin{frame}[fragile]{Using Convenience Wrapper}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{set.seed}\hlstd{(}\hlnum{618}\hlstd{)}
\hlstd{cboost} \hlkwb{=} \hlkwd{boostSplines}\hlstd{(}\hlkwc{data} \hlstd{= beer_data,} \hlkwc{target} \hlstd{=} \hlstr{"beer_consumption"}\hlstd{,}
  \hlkwc{loss} \hlstd{= LossAbsolute}\hlopt{$}\hlkwd{new}\hlstd{(),} \hlkwc{learning_rate} \hlstd{=} \hlnum{0.1}\hlstd{,} \hlkwc{iterations} \hlstd{=} \hlnum{5000L}\hlstd{,}
  \hlkwc{penalty} \hlstd{=} \hlnum{10}\hlstd{,} \hlkwc{oob_fraction} \hlstd{=} \hlnum{0.3}\hlstd{,} \hlkwc{trace} \hlstd{=} \hlnum{2500L}\hlstd{)}
\end{alltt}
\begin{verbatim}
##    1/5000   risk = 24  oob_risk = 24   
## 2500/5000   risk = 0.6  oob_risk = 8.3   
## 5000/5000   risk = 0.44  oob_risk = 8.3   
## 
## 
## Train 5000 iterations in 18 Seconds.
## Final risk based on the train set: 0.44
\end{verbatim}
\end{kframe}
\end{knitrout}

\end{frame}

\begin{frame}[fragile]{Visualizing Results}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{gg1} \hlkwb{=} \hlstd{cboost}\hlopt{$}\hlkwd{plotInbagVsOobRisk}\hlstd{()}
\hlstd{gg2} \hlkwb{=} \hlstd{cboost}\hlopt{$}\hlkwd{plotFeatureImportance}\hlstd{()}

\hlstd{gridExtra}\hlopt{::}\hlkwd{grid.arrange}\hlstd{(gg1, gg2,} \hlkwc{ncol} \hlstd{=} \hlnum{2L}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}
\includegraphics[width=\textwidth]{figure/unnamed-chunk-7-1} 

\end{knitrout}

\end{frame}

\begin{frame}[fragile]{Visualizing Results}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{cboost}\hlopt{$}\hlkwd{train}\hlstd{(}\hlnum{2000L}\hlstd{)}

\hlstd{gg1} \hlkwb{=} \hlstd{cboost}\hlopt{$}\hlkwd{plotFeatureImportance}\hlstd{()}
\hlstd{gg2} \hlkwb{=} \hlstd{cboost}\hlopt{$}\hlkwd{plot}\hlstd{(}\hlstr{"age_spline"}\hlstd{,} \hlkwc{iters} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{50}\hlstd{,} \hlnum{100}\hlstd{,} \hlnum{500}\hlstd{,} \hlnum{1000}\hlstd{,} \hlnum{2000}\hlstd{,} \hlnum{4000}\hlstd{))}

\hlstd{gridExtra}\hlopt{::}\hlkwd{grid.arrange}\hlstd{(gg1, gg2,} \hlkwc{ncol} \hlstd{=} \hlnum{2L}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}


\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}
\includegraphics[width=\textwidth]{figure/unnamed-chunk-9-1} 

\end{knitrout}

\end{frame}

\begin{frame}[fragile]{Using the R6 Interface}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{cboost} \hlkwb{=} \hlstd{Compboost}\hlopt{$}\hlkwd{new}\hlstd{(}\hlkwc{data} \hlstd{= beer_data,} \hlkwc{target} \hlstd{=} \hlstr{"beer_consumption"}\hlstd{,}
  \hlkwc{loss} \hlstd{= LossQuantile}\hlopt{$}\hlkwd{new}\hlstd{(}\hlnum{0.9}\hlstd{),} \hlkwc{learning_rate} \hlstd{=} \hlnum{0.1}\hlstd{,} \hlkwc{oob_fraction} \hlstd{=} \hlnum{0.3}\hlstd{)}

\hlstd{cboost}\hlopt{$}\hlkwd{addBaselearner}\hlstd{(}\hlstr{"age"}\hlstd{,} \hlstr{"spline"}\hlstd{, BaselearnerPSpline)}
\hlstd{cboost}\hlopt{$}\hlkwd{addBaselearner}\hlstd{(}\hlstr{"country"}\hlstd{,} \hlstr{"category"}\hlstd{, BaselearnerPolynomial)}

\hlstd{cboost}\hlopt{$}\hlkwd{addLogger}\hlstd{(}\hlkwc{logger} \hlstd{= LoggerTime,} \hlkwc{use_as_stopper} \hlstd{=} \hlnum{TRUE}\hlstd{,} \hlkwc{logger_id} \hlstd{=} \hlstr{"time"}\hlstd{,}
  \hlkwc{max_time} \hlstd{=} \hlnum{100000}\hlstd{,} \hlkwc{time_unit} \hlstd{=} \hlstr{"microseconds"}\hlstd{)}

\hlstd{cboost}\hlopt{$}\hlkwd{train}\hlstd{(}\hlnum{10000}\hlstd{,} \hlkwc{trace} \hlstd{=} \hlnum{500}\hlstd{)}
\end{alltt}
\begin{verbatim}
##     1/10000   risk = 11  oob_risk = 10   time = 1   
##   500/10000   risk = 7.9  oob_risk = 8.2   time = 28144   
##  1000/10000   risk = 6.3  oob_risk = 6.6   time = 61596   
## 
## 
## Train 1457 iterations in 0 Seconds.
## Final risk based on the train set: 5.2
\end{verbatim}
\end{kframe}
\end{knitrout}

\end{frame}

\begin{frame}{Functionality Overview}

\begin{itemize}

  \item
    Base-learner

  \item
    Loss functions

  \item
    Logger/Stopper

  \item
    Custom loss function and base-learner via \texttt{R} or \texttt{C++} without recompiling the package

\end{itemize}

\end{frame}


\section{What's Next?}

\begin{frame}

\begin{itemize}
  \item
    Research on computational aspects of the algorithm:
    \begin{itemize}
      \item
        More stable base-learner selection process via resampling
      \item
        Base-learner selection for arbitrary performance measures
      \item
        Smarter and faster optimizers
    \end{itemize}

  \item
    Greater functionality:
    \begin{itemize}
      \item
        Functional data structures and loss functions
      \item
        Unbiased feature selection
      \item
        Effect decomposition into constant, linear, and non-linear
    \end{itemize}

    \item
      Reducing the memory load by applying binning to numerical features.

    \item
      Python API
\end{itemize}

\end{frame}



\begin{frame}[plain, standout]
  Questions?
\end{frame}


\end{document}
